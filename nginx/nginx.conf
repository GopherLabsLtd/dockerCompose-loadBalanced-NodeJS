# Some of the comments here are taken from https://nginx.org/en/docs/

# The optimal value depends on many factors including (but not limited to) the number of CPU cores,
# the number of hard disk drives that store data, and load pattern. When one is in doubt,
# setting it to the number of available CPU cores would be a good start (the value “auto” will try to autodetect it).
worker_processes  4;

# Keep logs of events http://nginx.org/en/docs/ngx_core_module.html#error_log
error_log /var/log/nginx-error.log info;

events {
    # It's the key to high performance - have a lot of connections available
    # To check your server's limits limits, run these 2 commands ["ulimit -Hn", "ulimit -Sn"]
    # Max # of clients = worker_connections * worker_processes
    # Total # of users you can serve per second = worker_processes * worker_connections / (keepalive_timeout * 2)
    worker_connections      2048;

    # Use epoll, an I/O processing method that can enhance performance an is commonly used within Linux
    # http://nginx.org/en/docs/events.html
    use epoll;

    # If multi_accept is disabled, a worker process will accept one new connection at a time.
    # Otherwise, a worker process will accept all new connections at a time.
    # http://nginx.org/en/docs/ngx_core_module.html#multi_accept
    multi_accept on;
}

http {
  # Our group of servers that will be loadbalanced by NGINX
  # 3 replicas of the same Node application
  upstream ping {
    # Each visitor's requests are routed to the same server, unless they change their IP Address
    ip_hash;

    # Our 3 replicated servers
    server ping1:80;
    server ping2:80;
    server ping3:80;
  }

  # The processing rate of requests coming from a single IP address
  # Create a rule to be used on defined server locations defined below inside "server {...}"
  limit_req_zone $binary_remote_addr zone=one:10m rate=18000r/m;

  # Allow X Connections per an IP address at a time
  # It is individually defined below inside "server {...}" for each location
  limit_conn_zone $binary_remote_addr zone=addr:10m;

  # Timeout for HTTP keep-alive connections
  # 
  # https://en.wikipedia.org/wiki/HTTP_persistent_connection
  keepalive_timeout 65;
  keepalive_requests 100000; # Amount of keep-alive connections to allow at a time

  # Allows using sendfile() to transfer data directly in the kernel space
  # http://nginx.org/en/docs/http/ngx_http_core_module.html#sendfile
  sendfile on;
  tcp_nopush on;    # Allows sending a file in full packets in FreeBSD & Linux
  tcp_nodelay on;   # Forces sockets to send the data they have in their buffer
  
  # Sets buffer size for reading client request body.
  # In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file
  client_body_buffer_size      128k;

  # Allow a maximum body size of the client request (specified in the “Content-Length” request header field)
  client_max_body_size         10m;

  # Allow up to this buffer size for reading client request headers. For most requests, a buffer of 1K bytes is enough
  client_header_buffer_size    1k;

  # A request line cannot exceed the size of one buffer, or the 414 (Request-URI Too Large) error is returned to the client
  large_client_header_buffers  4 4k;

  server {
      listen 80;
      
      # Hide the NGINX version on error pages and in the “Server” response header field
      server_tokens   off;
      
      # Enable gzip compression of static files
      gzip on;

      # Disable gzip for Internet Explorer v1-6
      gzip_disable "MSIE [1-6]\.";

      # Sets a gzip compression level of a response. Acceptable values are in the range from 1 to 9 (higher value means more compression)
      # Level 5 is very common 
      gzip_comp_level 5;

      # Depending on if gzip is supported by the client's browser, they either receive a compressed version of the file or an uncompressed one
      # Now if a compressed version is cached, and the browser does not support that, NGINX wouldn't know to lookup the origin
      # If the Vary header isn't in there, and might serve an unsupported file to the client
      gzip_vary on;

      # Sets the minimum length of a response that will be gzipped, determined only from the “Content-Length” response header field.
      gzip_min_length 1000;

      # Enables or disables gzipping of responses for proxied requests depending on the request and response
      gzip_proxied any;

      # Filetypes that would be gzipped, if the client's browser accepts encoding, and the file length is larger than the gzip_min_length above
      gzip_types text/html application/x-javascript text/css application/javascript text/javascript text/plain text/xml application/json application/vnd.ms-fontobject application/x-font-opentype application/x-font-truetype application/x-font-ttf application/xml font/eot font/opentype font/otf image/svg+xml image/vnd.microsoft.icon;
      
      # Sets the number and size of buffers used to compress a response. By default, the buffer size is equal to one memory page.
      # This is either 4K or 8K, depending on a platform.
      gzip_buffers 16 8k;
      
      # Any requests made to example.com/*
      location / {
          # Apply the "processing rate of requests coming from a single IP address" rule (determined above)
          limit_req zone=one;

          # Apply the "maximum number of connections from a single IP address" rule (determined above)
          limit_conn addr 10;
          
          # Map the requests to this URL (ping is our upstream - defined above)
          proxy_pass http://ping/;
          proxy_http_version 1.1;

          # Pass client's IP Address to the upstream server (can be used in loadbalancing to distribute the load based on IP Address)
          proxy_set_header   Host               $http_host;
          proxy_set_header   X-Real-IP          $remote_addr;
          proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
          proxy_set_header   X-Forwarded-Proto  $scheme;
          
          # Tell the upstream servers that the request was proxied through NGINX, no specific use case but can be useful
          proxy_set_header   X-NginX-Proxy    true;
          
          # When one of the replicated server is down (e.g if the container is being updated with the latest version and coming back up soon)
          # NGINX will only wait for 2 seconds to connect to it, and if not successful, will move on to another one
          proxy_connect_timeout      2;
          proxy_buffer_size          4k;
          proxy_buffers              4 32k;
          proxy_busy_buffers_size    64k;
          proxy_temp_file_write_size 64k;
          proxy_temp_path            /etc/nginx/proxy_temp;

          # Sets a timeout for transmitting a request to the proxied server.
          # The timeout is set only between two successive write/read operations, not for the transmission of the whole request.
          proxy_send_timeout 600;
          proxy_read_timeout 600;
      }
  }
}